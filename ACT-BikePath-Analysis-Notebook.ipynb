{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ACT Bike Infrastructure Project\n",
    "\n",
    "## Bike Paths and Street Lights Data Wrangling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import pygeohash as pgh\n",
    "\n",
    "from cross_arc_distance import cross_arc_distance_vectorised, haversine_vectorised\n",
    "import loader\n",
    "import common\n",
    "import sys\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "all_paths_df, bike_paths_df, pedestrian_paths_df, street_lights_df = loader.load_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wrangling bike path data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "## Make a copy for modification\n",
    "bike_paths_mod_df = bike_paths_df.copy()\n",
    "\n",
    "## Split 'the_geom' dict into two columns, dropping original\n",
    "bike_paths_mod_df = pd.concat([\n",
    "        bike_paths_mod_df.drop(['the_geom'], axis=1), \n",
    "        bike_paths_mod_df['the_geom'].apply(pd.Series)], axis=1)\n",
    "\n",
    "## Flatten the 'coordinates' list of lists by depth 1\n",
    "bike_paths_mod_df = bike_paths_mod_df.explode('coordinates')\n",
    "\n",
    "## Split every list of lists of pairs of coordinates in 'coordinates' into coordinate quadruples\n",
    "## Each quadruple is of the form [A_long, A_lat, B_long, B_lat]\n",
    "bike_paths_mod_df = bike_paths_mod_df.join(bike_paths_mod_df['coordinates']\n",
    "                              .apply(lambda x: [[i[0], i[1], j[0], j[1]] for i, j in zip(x, x[1:])])\n",
    "                              .explode().rename('coordinate_pair'))\n",
    "\n",
    "## Split the coordinates quadruples list into separate lat and long columns\n",
    "coordinate_pair_split = pd.DataFrame(\n",
    "        bike_paths_mod_df[\"coordinate_pair\"].to_list(), columns=[\n",
    "            \"pointA_longitude\", \n",
    "            \"pointA_latitude\", \n",
    "            \"pointB_longitude\", \n",
    "            \"pointB_latitude\"\n",
    "        ])\n",
    "\n",
    "## Append the separated lat and long columns to the original df\n",
    "## We must drop the index before joining the list onto the df, then reset index.\n",
    "bike_paths_mod_df = bike_paths_mod_df.reset_index().join(coordinate_pair_split).set_index('index')\n",
    "\n",
    "## Drop superfluous columns\n",
    "bike_paths_mod_df = bike_paths_mod_df.drop(['coordinates', 'coordinate_pair', 'type'], axis=1)\n",
    "\n",
    "## Define a unique path ID geohash based on the new path segment coordinates. Precision is high so we don't lose info.\n",
    "bike_paths_mod_df['path_segment_ID'] = \\\n",
    "        bike_paths_mod_df.apply(lambda x: pgh.encode(x['pointA_latitude'], x['pointA_longitude'], precision=17), axis=1).astype(str) + \\\n",
    "        bike_paths_mod_df.apply(lambda x: pgh.encode(x['pointB_latitude'], x['pointB_longitude'], precision=17), axis=1).astype(str)\n",
    "\n",
    "## Remove duplicate path entries. I assume these must have come from the original data.\n",
    "## There is one instance where we have the same path segments assigned to neighbouring different suburbs - meh\n",
    "bike_paths_mod_df = bike_paths_mod_df.drop_duplicates(['path_segment_ID'])\n",
    "\n",
    "\n",
    "## use haversine_vectorised to get the length of the segments from the points I've defined.\n",
    "bike_paths_mod_df['sub_segment_length'] = haversine_vectorised(np.deg2rad(bike_paths_mod_df['pointA_latitude']), np.deg2rad(bike_paths_mod_df['pointA_longitude']), \n",
    "                                                               np.deg2rad(bike_paths_mod_df['pointB_latitude']), np.deg2rad(bike_paths_mod_df['pointB_longitude']))\n",
    "\n",
    "bike_paths_mod_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       path_type path_surf ave_width seg_length  suburb      owner  \\\n",
       "index                                                                \n",
       "81     CYCLEPATH   BITUMEN       2.5   24.11545  AMAROO  ROADS_ACT   \n",
       "81     CYCLEPATH   BITUMEN       2.5   24.11545  AMAROO  ROADS_ACT   \n",
       "81     CYCLEPATH   BITUMEN       2.5   24.11545  AMAROO  ROADS_ACT   \n",
       "81     CYCLEPATH   BITUMEN       2.5   24.11545  AMAROO  ROADS_ACT   \n",
       "81     CYCLEPATH   BITUMEN       2.5   24.11545  AMAROO  ROADS_ACT   \n",
       "\n",
       "       pointA_longitude  pointA_latitude  pointB_longitude  pointB_latitude  \\\n",
       "index                                                                         \n",
       "81           149.124824       -35.176958        149.124812       -35.177008   \n",
       "81           149.124812       -35.177008        149.124806       -35.177035   \n",
       "81           149.124806       -35.177035        149.124810       -35.177061   \n",
       "81           149.124810       -35.177061        149.124838       -35.177097   \n",
       "81           149.124838       -35.177097        149.124896       -35.177148   \n",
       "\n",
       "                          path_segment_ID  sub_segment_length  \n",
       "index                                                          \n",
       "81     r3dpckjrk5xzgwgf0r3dpckjr5fre2ge5k            5.694729  \n",
       "81     r3dpckjr5fre2ge5kr3dpckjqgv6mk8r3u            3.012691  \n",
       "81     r3dpckjqgv6mk8r3ur3dpckjqgbmz5xh5x            2.976032  \n",
       "81     r3dpckjqgbmz5xh5xr3dpckjqs9f8d5n6q            4.730260  \n",
       "81     r3dpckjqs9f8d5n6qr3dpckjqmbjxg40tt            7.731752  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_type</th>\n",
       "      <th>path_surf</th>\n",
       "      <th>ave_width</th>\n",
       "      <th>seg_length</th>\n",
       "      <th>suburb</th>\n",
       "      <th>owner</th>\n",
       "      <th>pointA_longitude</th>\n",
       "      <th>pointA_latitude</th>\n",
       "      <th>pointB_longitude</th>\n",
       "      <th>pointB_latitude</th>\n",
       "      <th>path_segment_ID</th>\n",
       "      <th>sub_segment_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>CYCLEPATH</td>\n",
       "      <td>BITUMEN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>24.11545</td>\n",
       "      <td>AMAROO</td>\n",
       "      <td>ROADS_ACT</td>\n",
       "      <td>149.124824</td>\n",
       "      <td>-35.176958</td>\n",
       "      <td>149.124812</td>\n",
       "      <td>-35.177008</td>\n",
       "      <td>r3dpckjrk5xzgwgf0r3dpckjr5fre2ge5k</td>\n",
       "      <td>5.694729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>CYCLEPATH</td>\n",
       "      <td>BITUMEN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>24.11545</td>\n",
       "      <td>AMAROO</td>\n",
       "      <td>ROADS_ACT</td>\n",
       "      <td>149.124812</td>\n",
       "      <td>-35.177008</td>\n",
       "      <td>149.124806</td>\n",
       "      <td>-35.177035</td>\n",
       "      <td>r3dpckjr5fre2ge5kr3dpckjqgv6mk8r3u</td>\n",
       "      <td>3.012691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>CYCLEPATH</td>\n",
       "      <td>BITUMEN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>24.11545</td>\n",
       "      <td>AMAROO</td>\n",
       "      <td>ROADS_ACT</td>\n",
       "      <td>149.124806</td>\n",
       "      <td>-35.177035</td>\n",
       "      <td>149.124810</td>\n",
       "      <td>-35.177061</td>\n",
       "      <td>r3dpckjqgv6mk8r3ur3dpckjqgbmz5xh5x</td>\n",
       "      <td>2.976032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>CYCLEPATH</td>\n",
       "      <td>BITUMEN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>24.11545</td>\n",
       "      <td>AMAROO</td>\n",
       "      <td>ROADS_ACT</td>\n",
       "      <td>149.124810</td>\n",
       "      <td>-35.177061</td>\n",
       "      <td>149.124838</td>\n",
       "      <td>-35.177097</td>\n",
       "      <td>r3dpckjqgbmz5xh5xr3dpckjqs9f8d5n6q</td>\n",
       "      <td>4.730260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>CYCLEPATH</td>\n",
       "      <td>BITUMEN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>24.11545</td>\n",
       "      <td>AMAROO</td>\n",
       "      <td>ROADS_ACT</td>\n",
       "      <td>149.124838</td>\n",
       "      <td>-35.177097</td>\n",
       "      <td>149.124896</td>\n",
       "      <td>-35.177148</td>\n",
       "      <td>r3dpckjqs9f8d5n6qr3dpckjqmbjxg40tt</td>\n",
       "      <td>7.731752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wrangling street light data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "## Make a copy for modification\n",
    "street_lights_mod_df = street_lights_df.copy()\n",
    "\n",
    "## Append a Boolean column to our street light data, and a distance column for later\n",
    "street_lights_mod_df['close_to_path'] = False\n",
    "street_lights_mod_df['distance_nearest_path'] = np.inf\n",
    "\n",
    "## Are there any lights that are in a suburb which contains no bike paths?\n",
    "bike_path_suburbs = bike_paths_mod_df['suburb'].str.lower().unique()\n",
    "street_light_suburbs = street_lights_mod_df['suburb'].str.lower().unique()\n",
    "\n",
    "## If so, remove the street lights in suburbs that contain no bike paths\n",
    "street_lights_no_bike_paths = list(set(street_light_suburbs) - set(bike_path_suburbs))\n",
    "street_lights_mod_df = street_lights_mod_df[~street_lights_mod_df['suburb']\n",
    "                        .str.lower()\n",
    "                        .isin(street_lights_no_bike_paths)]\n",
    "\n",
    "## Split the 'location' dict column into separate columns (ensure they are of numerical type)\n",
    "street_lights_mod_df = pd.concat([\n",
    "    street_lights_mod_df.drop(['location'], axis=1), \n",
    "    street_lights_mod_df['location'].apply(pd.Series)], axis=1)\n",
    "\n",
    "street_lights_mod_df[\"latitude\"] = pd.to_numeric(street_lights_mod_df[\"latitude\"])\n",
    "street_lights_mod_df[\"longitude\"] = pd.to_numeric(street_lights_mod_df[\"longitude\"])\n",
    "\n",
    "street_lights_mod_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               column_type :@computed_region_h8vr_r9vc     suburb  \\\n",
       "0             Rigid column                         104  WANNIASSA   \n",
       "1             Rigid column                          67   HARRISON   \n",
       "2                  VICPOLE                          89  GUNGAHLIN   \n",
       "3  Energy Absorbing column                          83       CITY   \n",
       "4             FORDE COLUMN                          19     WRIGHT   \n",
       "\n",
       "                                     address outreach_arm_length lamp_count  \\\n",
       "0                                        NaN                 NaN        NaN   \n",
       "1                                        NaN                 NaN        NaN   \n",
       "2                           HORSE PARK DRIVE        4.5 M SINGLE          1   \n",
       "3  VERITY LANE BTWN EAST ROW & NTHBOURNE AVE          3.5 M TWIN          2   \n",
       "4                          JOHN GORTON DRIVE        3.0 M SINGLE          1   \n",
       "\n",
       "              lamp_type     height          luminaire column_material  \\\n",
       "0                   NaN        NaN                NaN             NaN   \n",
       "1                   NaN        NaN                NaN             NaN   \n",
       "2  LIGHT EMITTING DIODE  12 metres  SYLVANIA ROAD LED             NaN   \n",
       "3          METAL HALIDE   5 metres            SPECIAL  STEEL ORDINARY   \n",
       "4  LIGHT EMITTING DIODE   9 metres      PECAN NXT-36S             NaN   \n",
       "\n",
       "   close_to_path  distance_nearest_path   latitude  \\\n",
       "0          False                    inf -35.403386   \n",
       "1          False                    inf -35.206829   \n",
       "2          False                    inf -35.175655   \n",
       "3          False                    inf -35.279123   \n",
       "4          False                    inf -35.314926   \n",
       "\n",
       "                                       human_address  needs_recoding  \\\n",
       "0  {\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...           False   \n",
       "1  {\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...           False   \n",
       "2  {\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...           False   \n",
       "3  {\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...           False   \n",
       "4  {\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...           False   \n",
       "\n",
       "    longitude  \n",
       "0  149.094254  \n",
       "1  149.149040  \n",
       "2  149.139648  \n",
       "3  149.129941  \n",
       "4  149.032875  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_type</th>\n",
       "      <th>:@computed_region_h8vr_r9vc</th>\n",
       "      <th>suburb</th>\n",
       "      <th>address</th>\n",
       "      <th>outreach_arm_length</th>\n",
       "      <th>lamp_count</th>\n",
       "      <th>lamp_type</th>\n",
       "      <th>height</th>\n",
       "      <th>luminaire</th>\n",
       "      <th>column_material</th>\n",
       "      <th>close_to_path</th>\n",
       "      <th>distance_nearest_path</th>\n",
       "      <th>latitude</th>\n",
       "      <th>human_address</th>\n",
       "      <th>needs_recoding</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rigid column</td>\n",
       "      <td>104</td>\n",
       "      <td>WANNIASSA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>-35.403386</td>\n",
       "      <td>{\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...</td>\n",
       "      <td>False</td>\n",
       "      <td>149.094254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rigid column</td>\n",
       "      <td>67</td>\n",
       "      <td>HARRISON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>-35.206829</td>\n",
       "      <td>{\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...</td>\n",
       "      <td>False</td>\n",
       "      <td>149.149040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VICPOLE</td>\n",
       "      <td>89</td>\n",
       "      <td>GUNGAHLIN</td>\n",
       "      <td>HORSE PARK DRIVE</td>\n",
       "      <td>4.5 M SINGLE</td>\n",
       "      <td>1</td>\n",
       "      <td>LIGHT EMITTING DIODE</td>\n",
       "      <td>12 metres</td>\n",
       "      <td>SYLVANIA ROAD LED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>-35.175655</td>\n",
       "      <td>{\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...</td>\n",
       "      <td>False</td>\n",
       "      <td>149.139648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Energy Absorbing column</td>\n",
       "      <td>83</td>\n",
       "      <td>CITY</td>\n",
       "      <td>VERITY LANE BTWN EAST ROW &amp; NTHBOURNE AVE</td>\n",
       "      <td>3.5 M TWIN</td>\n",
       "      <td>2</td>\n",
       "      <td>METAL HALIDE</td>\n",
       "      <td>5 metres</td>\n",
       "      <td>SPECIAL</td>\n",
       "      <td>STEEL ORDINARY</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>-35.279123</td>\n",
       "      <td>{\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...</td>\n",
       "      <td>False</td>\n",
       "      <td>149.129941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FORDE COLUMN</td>\n",
       "      <td>19</td>\n",
       "      <td>WRIGHT</td>\n",
       "      <td>JOHN GORTON DRIVE</td>\n",
       "      <td>3.0 M SINGLE</td>\n",
       "      <td>1</td>\n",
       "      <td>LIGHT EMITTING DIODE</td>\n",
       "      <td>9 metres</td>\n",
       "      <td>PECAN NXT-36S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "      <td>-35.314926</td>\n",
       "      <td>{\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...</td>\n",
       "      <td>False</td>\n",
       "      <td>149.032875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find lights that are close to bike paths"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "## Cutoff radius in metres. Lights at a distance < cutoff will be added to our output.\n",
    "cutoff = common.cutoff\n",
    "\n",
    "output_filename = common.lights_close_to_paths_data\n",
    "street_lights = np.array(street_lights_mod_df[['close_to_path', 'latitude', 'longitude', 'distance_nearest_path']])\n",
    "bike_paths = np.array(bike_paths_mod_df[['pointA_longitude', 'pointA_latitude', 'pointB_longitude', 'pointB_latitude', 'path_segment_ID']])\n",
    "total = len(bike_paths)\n",
    "\n",
    "## I have to chunk the vectorised bike_path data, because vector is too big!\n",
    "for i in range(len(bike_paths)-1):\n",
    "\n",
    "    ## Select the chunk. We will test the distance between each light and this chunk.\n",
    "    bike_paths_iter = bike_paths[i:i+1]\n",
    "    combinations = it.product(street_lights, bike_paths_iter)\n",
    "    result = np.array([np.hstack(i) for i in combinations])\n",
    "\n",
    "    ## Convert latitude and longitude points into radians\n",
    "    pointA_lat, pointA_long, pointB_lat, pointB_long, pointC_lat, pointC_long = map(np.deg2rad, [\n",
    "        result[:,5].astype(float), result[:,4].astype(float), result[:,7].astype(float), \n",
    "        result[:,6].astype(float), result[:,1].astype(float), result[:,2].astype(float)\n",
    "        ])\n",
    "\n",
    "    ## Calculate the cross-arc distance array between the bike path segments chunk and the light array\n",
    "    distance, segment_length = cross_arc_distance_vectorised(pointA_lat, pointA_long, pointB_lat, pointB_long, pointC_lat, pointC_long)\n",
    "\n",
    "    ## Find street lights, path segments, and distances such that distance is < our cutoff and stack these with their positions\n",
    "    street_light_close = np.array(np.where(distance < cutoff, True, False))\n",
    "    \n",
    "    light_lat_array, light_long_array = result[:,1].astype(float), result[:,2].astype(float)\n",
    "    path_segmentA_lat, path_segmentA_long = result[:,5].astype(float), result[:,4].astype(float)\n",
    "    path_segmentB_lat, path_segmentB_long = result[:,7].astype(float), result[:,6].astype(float)\n",
    "    path_segment_ID = result[:,8]\n",
    "\n",
    "    output_lights = np.column_stack((light_lat_array, light_long_array, street_light_close, \n",
    "                                    distance, path_segmentA_lat, path_segmentA_long, \n",
    "                                    path_segmentB_lat, path_segmentB_long, segment_length, path_segment_ID))\n",
    "\n",
    "    ## Convert array to df, then keep only rows of df where close_to_path is True, and append to output\n",
    "    output_lights_df = pd.DataFrame(output_lights, columns=[\"light_lat\", \"light_long\", \"close_to_path\", \n",
    "                                                            \"distance_nearest_path\", \"path_segmentA_lat\", \"path_segmentA_long\",\n",
    "                                                            \"path_segmentB_lat\", \"path_segmentB_long\", \"path_segment_length\", \"path_segment_ID\"])\n",
    "    output_lights_df['close_to_path'] = output_lights_df['close_to_path'].astype('bool')\n",
    "    lights_close_to_path_df = output_lights_df[output_lights_df['close_to_path']]\n",
    "    lights_close_to_path_df.to_csv(output_filename, mode='a', header=False)\n",
    "    \n",
    "    sys.stdout.write(\"\\r\" + f\"{i}/{total}\")\n",
    "    sys.stdout.flush()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "97409/97411"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Which paths are not close to any lights?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "## We will load the dataset from the above, for the sake of time.\n",
    "lights_close_to_path_df = pd.read_csv(common.lights_close_to_paths_data, index_col=None, header=None, \n",
    "                names=[\"index\", \"light_latitude\", \"light_longitude\", \"close_to_path\", \"distance_to_path\",\n",
    "                \"pathA_latitude\", \"pathA_longitude\", \"pathB_latitude\", \"pathB_longitude\", \"path_segment_length\", \"path_segment_ID\"])\n",
    "\n",
    "## These are all the lights close to paths, grouped by path.\n",
    "lights_close_to_path_df.groupby(by=['path_segment_ID']).apply(lambda a: a.drop(['path_segment_ID'], axis=1)[:])\n",
    "\n",
    "## which path segments ids are in bike_paths_mod_df['path_segment_ID'] and not in lights_close_to_path_df['path_segment_ID']\n",
    "## Because there will potentially be multiple light+path entries for a given path, de-duplicate lights_close_to_path on path_segment_ID\n",
    "paths_not_close_to_lights = bike_paths_mod_df.merge(lights_close_to_path_df.drop_duplicates(subset=['path_segment_ID']), on=['path_segment_ID'], how='left', indicator=True)\n",
    "paths_not_close_to_lights = paths_not_close_to_lights[paths_not_close_to_lights['_merge'] == 'left_only'] ## this will give only those in bike_paths_mod_df, not in lights_ or both\n",
    "\n",
    "paths_close_to_lights = bike_paths_mod_df.merge(lights_close_to_path_df.drop_duplicates(subset=['path_segment_ID']), on=['path_segment_ID'], how='left', indicator=True)\n",
    "paths_close_to_lights = paths_close_to_lights[paths_close_to_lights['_merge'] == 'both'] ## this will give paths only in lights_, not in both or bike_paths\n",
    "\n",
    "columns_of_interest = ['pointA_latitude', 'pointA_longitude', 'pointB_latitude', 'pointB_longitude', 'path_segment_ID', 'sub_segment_length']\n",
    "paths_not_close_to_lights = paths_not_close_to_lights[columns_of_interest]\n",
    "paths_close_to_lights = paths_close_to_lights[columns_of_interest]\n",
    "\n",
    "paths_not_close_to_lights.to_csv(common.paths_not_close_to_light_data)\n",
    "paths_close_to_lights.to_csv(common.paths_close_to_light_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(f\"There are {len(bike_paths_mod_df)} unique path segments, and {len(street_lights_df)} unique lights, making a total of {len(bike_paths_mod_df)*len(street_lights_df)} combinations\")\n",
    "print(f\"Of these combinations, there are {len(lights_close_to_path_df)} street light + path pairs that are within a {common.cutoff}m cutoff\")\n",
    "print(f\"There are {len(paths_not_close_to_lights)} path segments that have zero lights within that cutoff, or {(len(paths_not_close_to_lights)/len(bike_paths_mod_df))*100}% that are entirely unlit (by number of segments, not lengths)\")\n",
    "print(f\"Naturally, this means there are {len(paths_close_to_lights)} path segments that have lights within that cutoff, or {(len(paths_close_to_lights)/len(bike_paths_mod_df))*100}% that are lit\")\n",
    "print(f\"The length of all bike paths in the ACT is {bike_paths_mod_df['sub_segment_length'].sum()}m, of which {paths_not_close_to_lights['sub_segment_length'].sum()}, or {(paths_not_close_to_lights['sub_segment_length'].sum()/bike_paths_mod_df['sub_segment_length'].sum())*100}%, is unlit\")\n",
    "print(f\"Conversely, the length of all bike paths in the ACT is {bike_paths_mod_df['sub_segment_length'].sum()}m, of which {paths_close_to_lights['sub_segment_length'].sum()}, or {(paths_close_to_lights['sub_segment_length'].sum()/bike_paths_mod_df['sub_segment_length'].sum())*100}%, is lit\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 97411 unique path segments, and 81228 unique lights, making a total of 7912500708 combinations\n",
      "Of these combinations, there are 26602 street light + path pairs that are within a 10m cutoff\n",
      "There are 75109 path segments that have zero lights within that cutoff, or 77.10525505333074% that are entirely unlit (by number of segments, not lengths)\n",
      "Naturally, this means there are 22302 path segments that have lights within that cutoff, or 22.894744946669267% that are lit\n",
      "The length of all bike paths in the ACT is 498859.7229937521m, of which 314678.5106914509, or 63.079558478484756%, is unlit\n",
      "Conversely, the length of all bike paths in the ACT is 498859.7229937521m, of which 184181.21230230108, or 36.92044152151522%, is lit\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}